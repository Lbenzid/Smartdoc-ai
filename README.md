# Smartdoc-ai ğŸ¤–ğŸ“„

Smartdoc-ai est un assistant RAG (Retrieval-Augmented Generation) multimodal capable de traiter des documents texte et audio. Il a Ã©tÃ© conÃ§u pour indexer, transcrire, analyser et interroger des contenus complexes via une interface CLI. Ce projet s'appuie sur des technologies avancÃ©es telles que FAISS, Whisper, Langchain, Sentence-Transformers et des LLMs open source (TinyLlama, Mistral).

# Objectifs du projet

Proposer un assistant capable de traiter aussi bien des podcasts que des textes.

Mettre en Å“uvre un systÃ¨me RAG complet en local.

Tester diffÃ©rents LLMs : GPT-4o, TinyLlama, Mistral.

DÃ©montrer ma capacitÃ© Ã  faire face aux difficultÃ©s (API payante, quotas, push Git, etc.).

# Architecture globale
Smartdoc-ai/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ audio/             # Fichiers .mp3 ou .wav Ã  transcrire
â”‚   â”œâ”€â”€ docs/              # Transcriptions au format .txt
â”‚   â””â”€â”€ index/            # Index FAISS + noms de documents
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ transcription.py   # Transcription audio avec Whisper
â”‚   â”œâ”€â”€ embed_documents.py # Vectorisation et crÃ©ation de l'index FAISS
â”‚   â””â”€â”€ rag_hf.py         # Pipeline RAG avec LLM open-source
â”œâ”€â”€ .env                   # ClÃ©s API (OpenAI, HuggingFace)
â””â”€â”€ README.md

# FonctionnalitÃ©s principales

1. Transcription audio (Whisper)

Lecture des fichiers audio/*.mp3

Transcription avec Whisper (base) ou medium

Sauvegarde en .txt dans data/docs/

2. Indexation vectorielle (FAISS + SBERT)

Embedding des textes avec all-MiniLM-L6-v2

Stockage des vecteurs dans un index FAISS

Sauvegarde des noms pour retrouver les contextes

3. RAG avec LLM local (TinyLlama / Mistral)

Interrogation par l'utilisateur via la console

RequÃªte vectorielle sur les documents

Construction d'un prompt contextuel

GÃ©nÃ©ration de rÃ©ponses pertinentes

# LLMs testÃ©s:
               
ModÃ¨le Â 	Â  Â  Â Langue	Poids Â 	Temps de rÃ©ponse	 Â Support du franÃ§ais 	Â  Â  Â Remarques
GPT-4o (API) Â 	ğŸ‡«ğŸ‡·/ğŸ‡ºğŸ‡¸ Â  Â 	Â  Â  Â  Â  Â cloud 	 Â  Rapide Â  Â 	Â  Â  Â Excellent 	TrÃ¨s pertinent mais dÃ©pend d'un quota payant
TinyLlama-1.1B	ğŸ‡ºğŸ‡¸ uniquement Â 	Â ~1.1B Â 	 Â  Moyen Â  Â  Â 	 LimitÃ© Â  Â  Â 	LÃ©ger, rapide, mais mauvaise comprÃ©hension du franÃ§ais
Mistral-7B Â  Â  	Â  Â  Â  Â ğŸ‡«ğŸ‡·/ğŸ‡ºğŸ‡¸ Â  Â  Â 	~7B Â  Â 	Â  Lent (CPU) Â  Â  Â 	 Â Bon support Â  	Â  Â  RecommandÃ© si GPU ou version quantisÃ©e disponible


# ProblÃ¨mes rencontrÃ©s et solutions apportÃ©es: 

ProblÃ¨me Â  Â  Â  	Â                                 Solution apportÃ©e
Quota API GPT-4o dÃ©passÃ© Â  Â  	                 Migration vers LLM open-source (TinyLlama puis Mistral)
ProblÃ¨mes de push (error 408, broken pipe) Â  	 Nettoyage Git, suppression fichiers lourds, push via SSH
Prompt trop long pour les LLMs Â  Â  Â  	Â         Limitation Ã  2500 caractÃ¨res et top 3 documents (FAISS)
ModÃ¨le ne supporte pas le franÃ§ais Â  Â 	Â  Â       Test de plusieurs LLMs jusqu'Ã  Mistral pour support natif

# ExÃ©cution du projet (en local) :

1-Cloner le repo : git clone git@github.com:Lbenzid/Smartdoc-ai.git
cd Smartdoc-ai


2-CrÃ©er un environnement Python:
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt


3-Configurer les clÃ©s API dans un .env:
OPENAI_API_KEY=sk-...
HUGGINGFACEHUB_API_TOKEN=hf_...

4-Transcrire les audios: python src/transcription.py

5-Indexer les documents: python src/embed_documents.py

6-Lancer le RAG avec LLM local: python src/rag_hf.py

# Exemples de questions posÃ©es : 
Quel est le thÃ¨me principal du document ?

Quels sont les risques Ã©voquÃ©s liÃ©s Ã  lâ€™IA dans lâ€™art ?

Peux-tu rÃ©sumer ce podcast en 3 phrases ?

Le document fait-il rÃ©fÃ©rence Ã  des lois ou entreprises ?

# Perspectives d'Ã©volution

Interface web avec Gradio ou Streamlit

Support multi-documents et multi-langues

AmÃ©lioration du prompt engineering

Ajout de la recherche sÃ©mantique hybride (BM25 + embeddings)


Projet open source rÃ©alisÃ© par @Lbenzid âœ¨

