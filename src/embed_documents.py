from pathlib import Path
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle

DOCS_DIR = Path("data/docs")
INDEX_DIR = Path("data/index")
INDEX_DIR.mkdir(parents=True, exist_ok=True)

# Mod√®le d'embedding (petit et rapide)
model = SentenceTransformer("all-MiniLM-L6-v2")

# Charger les textes
docs = []
names = []

for file in DOCS_DIR.glob("*.txt"):
    text = file.read_text(encoding="utf-8")
    docs.append(text)
    names.append(file.stem)

print(f"üîç {len(docs)} documents √† indexer.")

# Calculer les embeddings
embeddings = model.encode(docs)

# Cr√©ation de l'index FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))

# Sauvegarder l'index
faiss.write_index(index, str(INDEX_DIR / "faiss_index.index"))

# Sauvegarder les noms associ√©s
with open(INDEX_DIR / "doc_names.pkl", "wb") as f:
    pickle.dump(names, f)

print("‚úÖ Index FAISS cr√©√© et sauvegard√©.")
